{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96a9ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class LossAndDerivatives:\n",
    "    @staticmethod\n",
    "    def mse(X, Y, w):\n",
    "        \"\"\"\n",
    "        X : numpy array of shape (`n_observations`, `n_features`)\n",
    "        Y : numpy array of shape (`n_observations`, `target_dimentionality`) or (`n_observations`,)\n",
    "        w : numpy array of shape (`n_features`, `target_dimentionality`) or (`n_features`,)\n",
    "        Return : float\n",
    "            single number with MSE value of linear model (X.dot(w)) with no bias term\n",
    "            on the selected dataset.\n",
    "        \n",
    "        Comment: If Y is two-dimentional, average the error over both dimentions.\n",
    "        \"\"\"\n",
    "\n",
    "        return np.mean((X.dot(w) - Y)**2)\n",
    "\n",
    "    @staticmethod\n",
    "    def mae(X, Y, w):\n",
    "        \"\"\"\n",
    "        X : numpy array of shape (`n_observations`, `n_features`)\n",
    "        Y : numpy array of shape (`n_observations`, `target_dimentionality`) or (`n_observations`,)\n",
    "        w : numpy array of shape (`n_features`, `target_dimentionality`) or (`n_features`,)\n",
    "                \n",
    "        Return: float\n",
    "            single number with MAE value of linear model (X.dot(w)) with no bias term\n",
    "            on the selected dataset.\n",
    "        Comment: If Y is two-dimentional, average the error over both dimentions.\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE    \n",
    "        return np.mean(abs(X.dot(w)-Y))\n",
    "\n",
    "    @staticmethod\n",
    "    def l2_reg(w):\n",
    "        \"\"\"\n",
    "        w : numpy array of shape (`n_features`, `target_dimentionality`) or (`n_features`,)\n",
    "        Return: float\n",
    "            single number with sum of squared elements of the weight matrix ( \\sum_{ij} w_{ij}^2 )\n",
    "        Computes the L2 regularization term for the weight matrix w.\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        return np.sum(w**2)\n",
    "\n",
    "    @staticmethod\n",
    "    def l1_reg(w):\n",
    "        \"\"\"\n",
    "        w : numpy array of shape (`n_features`, `target_dimentionality`)\n",
    "        Return : float\n",
    "            single number with sum of the absolute values of the weight matrix ( \\sum_{ij} |w_{ij}| )\n",
    "        \n",
    "        Computes the L1 regularization term for the weight matrix w.\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        return np.sum(abs(w))\n",
    "\n",
    "    @staticmethod\n",
    "    def no_reg(w):\n",
    "        \"\"\"\n",
    "        Simply ignores the regularization\n",
    "        \"\"\"\n",
    "        return 0.\n",
    "    \n",
    "    @staticmethod\n",
    "    def mse_derivative(X, Y, w):\n",
    "        \"\"\"\n",
    "        Optional task\n",
    "        X : numpy array of shape (`n_observations`, `n_features`)\n",
    "        Y : numpy array of shape (`n_observations`, `target_dimentionality`) or (`n_observations`,)\n",
    "        w : numpy array of shape (`n_features`, `target_dimentionality`) or (`n_features`,)\n",
    "        \n",
    "        Return : numpy array of same shape as `w`\n",
    "        Computes the MSE derivative for linear regression (X.dot(w)) with no bias term\n",
    "        w.r.t. w weight matrix.\n",
    "        \n",
    "        Please mention, that in case `target_dimentionality` > 1 the error is averaged along this\n",
    "        dimension as well, so you need to consider that fact in derivative implementation.\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        return 2*np.mean(X.dot(X.dot(w))-np.outer(X, Y))\n",
    "\n",
    "    @staticmethod\n",
    "    def mae_derivative(X, Y, w):\n",
    "        \"\"\"\n",
    "        Optional task\n",
    "        X : numpy array of shape (`n_observations`, `n_features`)\n",
    "        Y : numpy array of shape (`n_observations`, `target_dimentionality`) or (`n_observations`,)\n",
    "        w : numpy array of shape (`n_features`, `target_dimentionality`) or (`n_features`,)\n",
    "        \n",
    "        Return : numpy array of same shape as `w`\n",
    "        Computes the MAE derivative for linear regression (X.dot(w)) with no bias term\n",
    "        w.r.t. w weight matrix.\n",
    "        \n",
    "        Please mention, that in case `target_dimentionality` > 1 the error is averaged along this\n",
    "        dimension as well, so you need to consider that fact in derivative implementation.\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        return np.mean((X.dot(w)-y)/abs(X.dot(w) - y))\n",
    "\n",
    "    @staticmethod\n",
    "    def l2_reg_derivative(w):\n",
    "        \"\"\"\n",
    "        Optional task\n",
    "        w : numpy array of shape (`n_features`, `target_dimentionality`) or (`n_features`,)\n",
    "        Return : numpy array of same shape as `w`\n",
    "        Computes the L2 regularization term derivative w.r.t. the weight matrix w.\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        return 2*w\n",
    "\n",
    "    @staticmethod\n",
    "    def l1_reg_derivative(w):\n",
    "        \"\"\"\n",
    "        Optional task\n",
    "        Y : numpy array of shape (`n_observations`, `target_dimentionality`) or (`n_observations`,)\n",
    "        w : numpy array of shape (`n_features`, `target_dimentionality`) or (`n_features`,)\n",
    "        Return : numpy array of same shape as `w`\n",
    "        Computes the L1 regularization term derivative w.r.t. the weight matrix w.\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        return w/abs(w)\n",
    "\n",
    "    @staticmethod\n",
    "    def no_reg_derivative(w):\n",
    "        \"\"\"\n",
    "        Simply ignores the derivative\n",
    "        \"\"\"\n",
    "        return np.zeros_like(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f7cc490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  1.,  1., -1.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array([-1, 1, 1, -1])\n",
    "w/abs(w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
